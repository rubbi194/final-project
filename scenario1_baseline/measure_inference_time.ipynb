{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91a823b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\ultralytics\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model     | ms/img | FPS\n",
      "--------------------------\n",
      "yolov8n  | ERROR | list index out of range\n",
      "yolov8s  | ERROR | list index out of range\n",
      "yolov8m  | ERROR | list index out of range\n",
      "yolov8l  | ERROR | list index out of range\n",
      "yolov8x  | ERROR | list index out of range\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "import time, glob, cv2\n",
    "\n",
    "repo = \"rubbi194/trashdetection\"\n",
    "\n",
    "variants = [\"yolov8n\", \"yolov8s\", \"yolov8m\", \"yolov8l\", \"yolov8x\"]\n",
    "\n",
    "# ğŸ‘‰ Test images (replace with your real Scenario-3 test images)\n",
    "image_paths = glob.glob(\n",
    "    r\"c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\test\\images\\*.jpg\"\n",
    ")[:200]\n",
    "\n",
    "def measure(model_path):\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    img = cv2.imread(image_paths[0])\n",
    "    for _ in range(10):\n",
    "        model(img, verbose=False)\n",
    "\n",
    "    times = []\n",
    "    for p in image_paths:\n",
    "        img = cv2.imread(p)\n",
    "        t0 = time.perf_counter()\n",
    "        model(img, verbose=False)\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "\n",
    "    avg = sum(times)/len(times)\n",
    "    return avg*1000, 1/avg  # ms, FPS\n",
    "\n",
    "print(\"Model     | ms/img | FPS\")\n",
    "print(\"--------------------------\")\n",
    "\n",
    "for v in variants:\n",
    "    filename = f\"scenario3/{v}/best.pt\"\n",
    "\n",
    "    try:\n",
    "        model_path = hf_hub_download(\n",
    "            repo_id=repo,\n",
    "            filename=filename,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "\n",
    "        ms, fps = measure(model_path)\n",
    "        print(f\"{v:<8} | {ms:6.2f} | {fps:6.2f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"{v:<8} | ERROR | {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f98250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model to: C:\\Users\\User\\.cache\\huggingface\\hub\\models--rubbi194--trashdetection\\snapshots\\d97ddc1b31aa3ffb9207b6a89d84e21bf8e6f1b7\\scenario3\\yolov8l\\best.pt\n",
      "Found 0 test images\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No test images found, check the image_paths folder path.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(image_paths), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest images\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m image_paths:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo test images found, check the image_paths folder path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmeasure\u001b[39m(model_path):\n\u001b[0;32m     27\u001b[0m     model \u001b[38;5;241m=\u001b[39m YOLO(model_path)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: No test images found, check the image_paths folder path."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "import time, glob, cv2\n",
    "\n",
    "# HuggingFace repo\n",
    "repo = \"rubbi194/trashdetection\"\n",
    "\n",
    "# Download yolov8l Scenario 3 weights\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=repo,\n",
    "    filename=\"scenario3/yolov8l/best.pt\",\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "print(\"Downloaded model to:\", model_path)\n",
    "\n",
    "# ğŸ‘‰ Test images (make sure this folder really exists and has .jpg images)\n",
    "image_paths = glob.glob(\n",
    "    r\"c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\test\\images\\*.jpg\"\n",
    ")[:200]\n",
    "\n",
    "print(\"Found\", len(image_paths), \"test images\")\n",
    "if not image_paths:\n",
    "    raise RuntimeError(\"No test images found, check the image_paths folder path.\")\n",
    "\n",
    "def measure(model_path):\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # warm-up\n",
    "    img = cv2.imread(image_paths[0])\n",
    "    for _ in range(10):\n",
    "        model(img, verbose=False)\n",
    "\n",
    "    times = []\n",
    "    for p in image_paths:\n",
    "        img = cv2.imread(p)\n",
    "        t0 = time.perf_counter()\n",
    "        model(img, verbose=False)\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "\n",
    "    avg = sum(times) / len(times)\n",
    "    return avg * 1000, 1 / avg   # ms, FPS\n",
    "\n",
    "ms, fps = measure(model_path)\n",
    "print(f\"\\nRESULT for yolov8l (Scenario 3)\")\n",
    "print(f\"Average inference time: {ms:.2f} ms/image\")\n",
    "print(f\"FPS: {fps:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a07d2970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning for .jpg images...\n",
      "\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val10\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val12\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val13\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val18\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val26\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val27\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val28\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val29\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val3\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val31\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val34\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val35\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val37\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val39\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val4\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val40\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val41\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val5\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val7\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val8\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\runs\\detect\\val9\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\yolov8l\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\yolov8m\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\yolov8n\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\yolov8s\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario1_baseline\\yolov8x\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val11\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val12\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val13\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val14\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val15\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val18\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val19\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val20\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val21\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val22\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val5\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val6\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val7\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val8\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\runs\\detect\\val9\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\yolov8l\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\yolov8m\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\yolov8n\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\yolov8s\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario2\\yolov8x\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val10\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val11\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val12\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val13\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val14\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val16\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val18\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val2\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val20\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val21\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val4\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val5\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\runs\\detect\\val9\n",
      "   Example file: val_batch0_labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\yolov8l\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\yolov8m\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\yolov8n\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\yolov8s\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n",
      "ğŸ“ Found images in: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\yolov8x\\finetuning-1\n",
      "   Example file: labels.jpg\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ROOT = r\"c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\"\n",
    "\n",
    "print(\"Scanning for .jpg images...\\n\")\n",
    "\n",
    "found = False\n",
    "for folder, subdirs, files in os.walk(ROOT):\n",
    "    jpgs = [f for f in files if f.lower().endswith(\".jpg\")]\n",
    "    if jpgs:\n",
    "        found = True\n",
    "        print(\"ğŸ“ Found images in:\", folder)\n",
    "        print(\"   Example file:\", jpgs[0])\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "if not found:\n",
    "    print(\"âŒ No .jpg images found anywhere under the ROOT folder.\")\n",
    "    print(\"Please check if your images are .png or in another drive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9fdf638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image folder: C:/Users/User/Documents/Rabab/dataset/test--2/test_glare_fixed/images\n",
      "Total images found: 206\n",
      "Using 200 images for inference timing.\n",
      "\n",
      "Measuring inference time for each YOLOv8 variant...\n",
      "\n",
      "Downloading weights for yolov8n...\n",
      "yolov8n: 18.57 ms/image, 53.85 FPS\n",
      "\n",
      "Downloading weights for yolov8s...\n",
      "yolov8s: 25.08 ms/image, 39.86 FPS\n",
      "\n",
      "Downloading weights for yolov8m...\n",
      "yolov8m: 32.79 ms/image, 30.49 FPS\n",
      "\n",
      "Downloading weights for yolov8l...\n",
      "yolov8l: 38.10 ms/image, 26.24 FPS\n",
      "\n",
      "Downloading weights for yolov8x...\n",
      "yolov8x: 49.15 ms/image, 20.34 FPS\n",
      "\n",
      "\n",
      "=========== INFERENCE-TIME SUMMARY ===========\n",
      "Model        ms/image        FPS\n",
      "----------------------------------------------\n",
      "yolov8n         18.57      53.85\n",
      "yolov8s         25.08      39.86\n",
      "yolov8m         32.79      30.49\n",
      "yolov8l         38.10      26.24\n",
      "yolov8x         49.15      20.34\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "import glob, time, cv2\n",
    "\n",
    "# 1. HuggingFace repo and YOLO variants\n",
    "REPO = \"rubbi194/trashdetection\"\n",
    "VARIANTS = [\"yolov8n\", \"yolov8s\", \"yolov8m\", \"yolov8l\", \"yolov8x\"]\n",
    "\n",
    "# 2. Folder with test images  âœ… (from your screenshot)\n",
    "IMAGE_DIR = \"C:/Users/User/Documents/Rabab/dataset/test--2/test_glare_fixed/images\"\n",
    "\n",
    "# take all jpg & png in that folder\n",
    "image_paths = glob.glob(fr\"{IMAGE_DIR}\\*.jpg\") + glob.glob(fr\"{IMAGE_DIR}\\*.png\")\n",
    "\n",
    "print(\"Test image folder:\", IMAGE_DIR)\n",
    "print(\"Total images found:\", len(image_paths))\n",
    "if not image_paths:\n",
    "    raise RuntimeError(\"No .jpg or .png images found in IMAGE_DIR. Check the path or choose another folder.\")\n",
    "\n",
    "# (optional) limit to 200 images max\n",
    "image_paths = image_paths[:200]\n",
    "print(\"Using\", len(image_paths), \"images for inference timing.\\n\")\n",
    "\n",
    "def measure_inference_time(model_path: str):\n",
    "    \"\"\"Return (avg_ms_per_image, fps) for the given model.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # warm-up\n",
    "    img = cv2.imread(image_paths[0])\n",
    "    for _ in range(10):\n",
    "        _ = model(img, verbose=False)\n",
    "\n",
    "    times = []\n",
    "    for p in image_paths:\n",
    "        img = cv2.imread(p)\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model(img, verbose=False)\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "\n",
    "    avg_s = sum(times) / len(times)\n",
    "    avg_ms = avg_s * 1000.0\n",
    "    fps = 1.0 / avg_s\n",
    "    return avg_ms, fps\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Measuring inference time for each YOLOv8 variant...\\n\")\n",
    "for v in VARIANTS:\n",
    "    filename = f\"scenario3/{v}/best.pt\"\n",
    "    try:\n",
    "        print(f\"Downloading weights for {v}...\")\n",
    "        model_path = hf_hub_download(\n",
    "            repo_id=REPO,\n",
    "            filename=filename,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "        ms, fps = measure_inference_time(model_path)\n",
    "        results.append((v, ms, fps))\n",
    "        print(f\"{v}: {ms:.2f} ms/image, {fps:.2f} FPS\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR for {v}: {e}\\n\")\n",
    "\n",
    "print(\"\\n=========== INFERENCE-TIME SUMMARY ===========\")\n",
    "print(f\"{'Model':<10} {'ms/image':>10} {'FPS':>10}\")\n",
    "print(\"----------------------------------------------\")\n",
    "for name, ms, fps in results:\n",
    "    print(f\"{name:<10} {ms:10.2f} {fps:10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c50a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\ultralytics\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image folder: C:\\Users\\User\\Documents\\Rabab\\dataset\\Scenario 1\\no reflection\\test--3\\test\\images\n",
      "Total images found: 206\n",
      "Using 200 images for inference timing.\n",
      "\n",
      "Measuring inference time for each YOLOv8 variant...\n",
      "\n",
      "Downloading weights for yolov8n...\n",
      "yolov8n: 17.20 ms/image, 58.15 FPS\n",
      "\n",
      "Downloading weights for yolov8s...\n",
      "yolov8s: 23.96 ms/image, 41.73 FPS\n",
      "\n",
      "Downloading weights for yolov8m...\n",
      "yolov8m: 35.99 ms/image, 27.79 FPS\n",
      "\n",
      "Downloading weights for yolov8l...\n",
      "yolov8l: 35.42 ms/image, 28.23 FPS\n",
      "\n",
      "Downloading weights for yolov8x...\n",
      "yolov8x: 40.44 ms/image, 24.73 FPS\n",
      "\n",
      "\n",
      "=========== INFERENCE-TIME SUMMARY ===========\n",
      "Model        ms/image        FPS\n",
      "----------------------------------------------\n",
      "yolov8n         17.20      58.15\n",
      "yolov8s         23.96      41.73\n",
      "yolov8m         35.99      27.79\n",
      "yolov8l         35.42      28.23\n",
      "yolov8x         40.44      24.73\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "import glob, time, cv2\n",
    "\n",
    "# 1. HuggingFace repo and YOLO variants\n",
    "REPO = \"rubbi194/trashdetection\"\n",
    "VARIANTS = [\"yolov8n\", \"yolov8s\", \"yolov8m\", \"yolov8l\", \"yolov8x\"]\n",
    "\n",
    "# 2. Folder with test images  âœ… (from your screenshot)\n",
    "IMAGE_DIR = r\"C:\\Users\\User\\Documents\\Rabab\\dataset\\Scenario 1\\no reflection\\test--3\\test\\images\"\n",
    "\n",
    "# take all jpg & png in that folder\n",
    "image_paths = glob.glob(fr\"{IMAGE_DIR}\\*.jpg\") + glob.glob(fr\"{IMAGE_DIR}\\*.png\")\n",
    "\n",
    "print(\"Test image folder:\", IMAGE_DIR)\n",
    "print(\"Total images found:\", len(image_paths))\n",
    "if not image_paths:\n",
    "    raise RuntimeError(\"No .jpg or .png images found in IMAGE_DIR. Check the path or choose another folder.\")\n",
    "\n",
    "# (optional) limit to 200 images max\n",
    "image_paths = image_paths[:200]\n",
    "print(\"Using\", len(image_paths), \"images for inference timing.\\n\")\n",
    "\n",
    "def measure_inference_time(model_path: str):\n",
    "    \"\"\"Return (avg_ms_per_image, fps) for the given model.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # warm-up\n",
    "    img = cv2.imread(image_paths[0])\n",
    "    for _ in range(10):\n",
    "        _ = model(img, verbose=False)\n",
    "\n",
    "    times = []\n",
    "    for p in image_paths:\n",
    "        img = cv2.imread(p)\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model(img, verbose=False)\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "\n",
    "    avg_s = sum(times) / len(times)\n",
    "    avg_ms = avg_s * 1000.0\n",
    "    fps = 1.0 / avg_s\n",
    "    return avg_ms, fps\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Measuring inference time for each YOLOv8 variant...\\n\")\n",
    "for v in VARIANTS:\n",
    "    filename = f\"scenario3/{v}/best.pt\"\n",
    "    try:\n",
    "        print(f\"Downloading weights for {v}...\")\n",
    "        model_path = hf_hub_download(\n",
    "            repo_id=REPO,\n",
    "            filename=filename,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "        ms, fps = measure_inference_time(model_path)\n",
    "        results.append((v, ms, fps))\n",
    "        print(f\"{v}: {ms:.2f} ms/image, {fps:.2f} FPS\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR for {v}: {e}\\n\")\n",
    "\n",
    "print(\"\\n=========== INFERENCE-TIME SUMMARY ===========\")\n",
    "print(f\"{'Model':<10} {'ms/image':>10} {'FPS':>10}\")\n",
    "print(\"----------------------------------------------\")\n",
    "for name, ms, fps in results:\n",
    "    print(f\"{name:<10} {ms:10.2f} {fps:10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0109d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test image folder: C:\\Users\\User\\Documents\\Rabab\\dataset\\Scenario 3\\reflection\\test_glare_fixed\n",
      "Total images found: 203\n",
      "Using 200 images for inference timing.\n",
      "\n",
      "Measuring inference time for each YOLOv8 variant...\n",
      "\n",
      "Downloading weights for yolov8n...\n",
      "yolov8n: 12.97 ms/image, 77.12 FPS\n",
      "\n",
      "Downloading weights for yolov8s...\n",
      "yolov8s: 12.62 ms/image, 79.22 FPS\n",
      "\n",
      "Downloading weights for yolov8m...\n",
      "yolov8m: 15.06 ms/image, 66.38 FPS\n",
      "\n",
      "Downloading weights for yolov8l...\n",
      "yolov8l: 17.62 ms/image, 56.74 FPS\n",
      "\n",
      "Downloading weights for yolov8x...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 59\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading weights for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m model_path \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[0;32m     55\u001b[0m     repo_id\u001b[38;5;241m=\u001b[39mREPO,\n\u001b[0;32m     56\u001b[0m     filename\u001b[38;5;241m=\u001b[39mfilename,\n\u001b[0;32m     57\u001b[0m     repo_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     58\u001b[0m )\n\u001b[1;32m---> 59\u001b[0m ms, fps \u001b[38;5;241m=\u001b[39m \u001b[43mmeasure_inference_time\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m results\u001b[38;5;241m.\u001b[39mappend((v, ms, fps))\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mms\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ms/image, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfps\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m FPS\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 36\u001b[0m, in \u001b[0;36mmeasure_inference_time\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m     34\u001b[0m times \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m image_paths:\n\u001b[1;32m---> 36\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m     38\u001b[0m     _ \u001b[38;5;241m=\u001b[39m model(img, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\User\\.conda\\envs\\ultralytics\\lib\\site-packages\\ultralytics\\utils\\patches.py:26\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(filename, flags)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimread\u001b[39m(filename: \u001b[38;5;28mstr\u001b[39m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mIMREAD_COLOR):\n\u001b[0;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    Read an image from a file.\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;124;03m        (np.ndarray): The read image.\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from ultralytics import YOLO\n",
    "import glob, time, cv2\n",
    "\n",
    "# 1. HuggingFace repo and YOLO variants\n",
    "REPO = \"rubbi194/trashdetection\"\n",
    "VARIANTS = [\"yolov8n\", \"yolov8s\", \"yolov8m\", \"yolov8l\", \"yolov8x\"]\n",
    "\n",
    "# 2. Folder with test images  âœ… (from your screenshot)\n",
    "IMAGE_DIR = r\"C:\\Users\\User\\Documents\\Rabab\\dataset\\Scenario 3\\reflection\\test_glare_fixed\"\n",
    "\n",
    "\n",
    "# take all jpg & png in that folder\n",
    "image_paths = glob.glob(fr\"{IMAGE_DIR}\\*.jpg\") + glob.glob(fr\"{IMAGE_DIR}\\*.png\")\n",
    "\n",
    "print(\"Test image folder:\", IMAGE_DIR)\n",
    "print(\"Total images found:\", len(image_paths))\n",
    "if not image_paths:\n",
    "    raise RuntimeError(\"No .jpg or .png images found in IMAGE_DIR. Check the path or choose another folder.\")\n",
    "\n",
    "# (optional) limit to 200 images max\n",
    "image_paths = image_paths[:200]\n",
    "print(\"Using\", len(image_paths), \"images for inference timing.\\n\")\n",
    "\n",
    "def measure_inference_time(model_path: str):\n",
    "    \"\"\"Return (avg_ms_per_image, fps) for the given model.\"\"\"\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    # warm-up\n",
    "    img = cv2.imread(image_paths[0])\n",
    "    for _ in range(10):\n",
    "        _ = model(img, verbose=False)\n",
    "\n",
    "    times = []\n",
    "    for p in image_paths:\n",
    "        img = cv2.imread(p)\n",
    "        t0 = time.perf_counter()\n",
    "        _ = model(img, verbose=False)\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "\n",
    "    avg_s = sum(times) / len(times)\n",
    "    avg_ms = avg_s * 1000.0\n",
    "    fps = 1.0 / avg_s\n",
    "    return avg_ms, fps\n",
    "\n",
    "results = []\n",
    "\n",
    "print(\"Measuring inference time for each YOLOv8 variant...\\n\")\n",
    "for v in VARIANTS:\n",
    "    filename = f\"scenario3/{v}/best.pt\"\n",
    "    try:\n",
    "        print(f\"Downloading weights for {v}...\")\n",
    "        model_path = hf_hub_download(\n",
    "            repo_id=REPO,\n",
    "            filename=filename,\n",
    "            repo_type=\"model\"\n",
    "        )\n",
    "        ms, fps = measure_inference_time(model_path)\n",
    "        results.append((v, ms, fps))\n",
    "        print(f\"{v}: {ms:.2f} ms/image, {fps:.2f} FPS\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR for {v}: {e}\\n\")\n",
    "\n",
    "print(\"\\n=========== INFERENCE-TIME SUMMARY ===========\")\n",
    "print(f\"{'Model':<10} {'ms/image':>10} {'FPS':>10}\")\n",
    "print(\"----------------------------------------------\")\n",
    "for name, ms, fps in results:\n",
    "    print(f\"{name:<10} {ms:10.2f} {fps:10.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

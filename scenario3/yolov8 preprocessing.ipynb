{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdee8f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in My-First-Project-11 to yolov8:: 100%|██████████| 2714786/2714786 [02:29<00:00, 18211.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to My-First-Project-11 in yolov8:: 100%|██████████| 50878/50878 [00:27<00:00, 1871.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"2oeGI3QWbiYo6HNrErIp\")\n",
    "project = rf.workspace(\"aaaa-g4pgj\").project(\"my-first-project-pv3aw\")\n",
    "version = project.version(11)\n",
    "dataset = version.download(\"yolov8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cdfd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 22218/22218 [3:27:42<00:00,  1.78it/s]  \n",
      "Processing images: 100%|██████████| 1607/1607 [15:22<00:00,  1.74it/s]\n",
      "Processing images: 100%|██████████| 1608/1608 [15:08<00:00,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All glare-reduced images generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Preprocessing function you already tested ---\n",
    "def remove_glare_reflection(img_bgr):\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Adaptive glare mask\n",
    "    v_blur = cv2.GaussianBlur(v, (11, 11), 0)\n",
    "    thresh_val = np.percentile(v_blur, 98)\n",
    "    glare_mask = cv2.inRange(v_blur, thresh_val - 5, 255)\n",
    "    glare_mask = cv2.dilate(glare_mask, np.ones((5,5), np.uint8), iterations=2)\n",
    "    glare_mask = cv2.GaussianBlur(glare_mask, (9, 9), 0)\n",
    "\n",
    "    smooth = cv2.edgePreservingFilter(img_bgr, flags=1, sigma_s=80, sigma_r=0.3)\n",
    "\n",
    "    mask_norm = glare_mask.astype(np.float32) / 255.0\n",
    "    mask_norm = np.repeat(mask_norm[..., None], 3, axis=2)\n",
    "    blend = cv2.convertScaleAbs(img_bgr * (1 - mask_norm) + smooth * mask_norm)\n",
    "\n",
    "    inpaint_mask = cv2.inRange(v, 240, 255)\n",
    "    inpainted = cv2.inpaint(blend, inpaint_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    lab = cv2.cvtColor(inpainted, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=1.8, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    result = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess_split(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    for f in tqdm(files, desc=f\"Processing {os.path.basename(input_dir)}\"):\n",
    "        img = cv2.imread(os.path.join(input_dir, f))\n",
    "        if img is None:\n",
    "            continue\n",
    "        processed = remove_glare_reflection(img)\n",
    "        cv2.imwrite(os.path.join(output_dir, f), processed)\n",
    "\n",
    "\n",
    "# --- Apply to all YOLO splits ---\n",
    "dataset_path = dataset.location  # from Roboflow\n",
    "\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "for split in splits:\n",
    "    in_dir = os.path.join(dataset_path, split, \"images\")\n",
    "    out_dir = os.path.join(dataset_path, f\"{split}_glare_fixed\")\n",
    "    preprocess_split(in_dir, out_dir)\n",
    "\n",
    "print(\"✅ All glare-reduced images generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "806189e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created YAML file at: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\My-First-Project-11\\data_glare_fixed.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml, os\n",
    "\n",
    "data_yaml = {\n",
    "    'train': os.path.join(dataset_path, 'train_glare_fixed'),\n",
    "    'val': os.path.join(dataset_path, 'valid_glare_fixed'),\n",
    "    'test': os.path.join(dataset_path, 'test_glare_fixed'),\n",
    "    'names': ['trash', 'bottle', 'plastic_bag', 'can']  # adjust based on your dataset\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(dataset_path, 'data_glare_fixed.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f)\n",
    "\n",
    "print(\"✅ Created YAML file at:\", yaml_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6e8b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exposure_fuse(bgr):\n",
    "    # simulate bracketed exposures\n",
    "    def gamma(img, g):\n",
    "        inv = 1.0 / g\n",
    "        table = np.array([(i/255.0)**inv*255 for i in range(256)]).astype(\"uint8\")\n",
    "        return cv2.LUT(img, table)\n",
    "    imgs = [gamma(bgr, 0.7), bgr, gamma(bgr, 1.5)]\n",
    "    merge = cv2.createMergeMertens().process([i.astype(np.float32)/255.0 for i in imgs])\n",
    "    return (np.clip(merge,0,1)*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04253116",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

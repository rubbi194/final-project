{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdee8f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in test--2 to yolov8:: 100%|██████████| 130170/130170 [00:08<00:00, 14939.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to test--2 in yolov8:: 100%|██████████| 418/418 [00:00<00:00, 1348.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"2oeGI3QWbiYo6HNrErIp\")\n",
    "project = rf.workspace(\"aaaa-g4pgj\").project(\"test-xkimg\")\n",
    "version = project.version(2)\n",
    "dataset = version.download(\"yolov8\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31cdfd9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 0it [00:00, ?it/s]\n",
      "Processing images: 0it [00:00, ?it/s]\n",
      "Processing images: 100%|██████████| 206/206 [16:36<00:00,  4.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All glare-reduced images generated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Preprocessing function you already tested ---\n",
    "def remove_glare_reflection(img_bgr):\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "\n",
    "    # Adaptive glare mask\n",
    "    v_blur = cv2.GaussianBlur(v, (11, 11), 0)\n",
    "    thresh_val = np.percentile(v_blur, 98)\n",
    "    glare_mask = cv2.inRange(v_blur, thresh_val - 5, 255)\n",
    "    glare_mask = cv2.dilate(glare_mask, np.ones((5,5), np.uint8), iterations=2)\n",
    "    glare_mask = cv2.GaussianBlur(glare_mask, (9, 9), 0)\n",
    "\n",
    "    smooth = cv2.edgePreservingFilter(img_bgr, flags=1, sigma_s=80, sigma_r=0.3)\n",
    "\n",
    "    mask_norm = glare_mask.astype(np.float32) / 255.0\n",
    "    mask_norm = np.repeat(mask_norm[..., None], 3, axis=2)\n",
    "    blend = cv2.convertScaleAbs(img_bgr * (1 - mask_norm) + smooth * mask_norm)\n",
    "\n",
    "    inpaint_mask = cv2.inRange(v, 240, 255)\n",
    "    inpainted = cv2.inpaint(blend, inpaint_mask, 3, cv2.INPAINT_TELEA)\n",
    "\n",
    "    lab = cv2.cvtColor(inpainted, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(clipLimit=1.8, tileGridSize=(8, 8))\n",
    "    cl = clahe.apply(l)\n",
    "    merged = cv2.merge((cl, a, b))\n",
    "    result = cv2.cvtColor(merged, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def preprocess_split(input_dir, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.jpg', '.png', '.jpeg'))]\n",
    "    for f in tqdm(files, desc=f\"Processing {os.path.basename(input_dir)}\"):\n",
    "        img = cv2.imread(os.path.join(input_dir, f))\n",
    "        if img is None:\n",
    "            continue\n",
    "        processed = remove_glare_reflection(img)\n",
    "        cv2.imwrite(os.path.join(output_dir, f), processed)\n",
    "\n",
    "\n",
    "# --- Apply to all YOLO splits ---\n",
    "dataset_path = dataset.location  # from Roboflow\n",
    "\n",
    "splits = [\"train\", \"valid\", \"test\"]\n",
    "for split in splits:\n",
    "    in_dir = os.path.join(dataset_path, split, \"images\")\n",
    "    out_dir = os.path.join(dataset_path, f\"{split}_glare_fixed\")\n",
    "    preprocess_split(in_dir, out_dir)\n",
    "\n",
    "print(\"✅ All glare-reduced images generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "806189e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created YAML file at: c:\\Users\\User\\Documents\\Rabab\\repo\\final-project\\scenario3\\test--2\\data_glare_fixed.yaml\n"
     ]
    }
   ],
   "source": [
    "import yaml, os\n",
    "\n",
    "data_yaml = {\n",
    "    'train': os.path.join(dataset_path, 'train_glare_fixed'),\n",
    "    'val': os.path.join(dataset_path, 'valid_glare_fixed'),\n",
    "    'test': os.path.join(dataset_path, 'test_glare_fixed'),\n",
    "    'names': ['trash', 'bottle', 'plastic_bag', 'can']  # adjust based on your dataset\n",
    "}\n",
    "\n",
    "yaml_path = os.path.join(dataset_path, 'data_glare_fixed.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    yaml.dump(data_yaml, f)\n",
    "\n",
    "print(\"✅ Created YAML file at:\", yaml_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38766cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ultralytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
